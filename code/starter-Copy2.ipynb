{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "___Hello? Can anyone hear me?___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"https://media.giphy.com/media/xaMg6NGwH2fFS/giphy.gif\" alt=\"Title\" style=\"border: 5px solid #000000; padding: 10px; width: 250px; height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## There. Is that better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"http://bestanimations.com/Sci-Fi/Aliens/little-grey-extraterrestial-aliens-animated-gif-image-10.gif\" alt=\"Title\" style=\"border: 5px solid #000000; padding: 10px; width: 250px; height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Good... Hello fellow person. My name is Hugh Man. I am also a person like you! Here is a picture of me at a normal human party with my normal human friends!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"http://www.promvenues.com/blogs/media/Crazy%20Prom%20Themes%20for%20Teenagers%20to%20Spice%20up%20Their%20Party_142.jpg\" alt=\"Title\" style=\"border: 5px solid #000000; padding: 10px; width: 250px; height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Look how much fun we are having drinking everyday human liquids!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Anyways, I have sent this communication to ask you a few questions about normal human activities, that I also do. My human mother is very sick and doesn't get out from her two story Dutch Colonial condo as often as she would like. Here is a picture of her from yesterday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"http://previews.123rf.com/images/szefei/szefei1302/szefei130200062/18061194-Happy-mother-s-day-concept-Asian-senior-mother-showing-a-gift-and-carnation-flowers-at-home--Stock-Photo.jpg\" alt=\"Title\" style=\"border: 5px solid #000000; padding: 10px; width: 250px; height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## She was wondering about the state of technological / military advancement on your human planet. She is very fearful of planets with enough technology to shoot down class C starships from space. Can you help put her fears to rest? My assistant will beam the details to your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "___Beep___\n",
    "### Assistant here! I have updated your notebook with the proper protocols. Please follow the instructions provided.\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "* Access the 'conspiracy' site (https://www.reddit.com/r/conspiracy.json). You should get the first 25 entries from the subreddit right away.\n",
    "* Make sure to keep track of the entry position, title, and upvotes for each entry in the subreddit\n",
    "* Crawl through each url. Extract all the text from each paragraph (they have a <**p**> tag). If there is no url, skip this step.\n",
    "* Crawl through each url. Extract all the links from each link tag (they have an <**a**> tag). If there is no url, skip this step.\n",
    "\n",
    "*** Bonus ***\n",
    "\n",
    "* Crawl through each of the comments. Extract all the text from the body keys of each comment\n",
    "\n",
    "#### Tips\n",
    "\n",
    "* Each entry on the site contains a key called \"permalink\" add it to your base url to navigate to that link's comments\n",
    "* Each entry on the site contains a key called \"url\". Use this link to navigate to the page described in the post\n",
    "\n",
    "<br>\n",
    "** Base Url => https://www.reddit.com **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "base = 'https://www.reddit.com'\n",
    "soup = BeautifulSoup(urllib2.urlopen('https://www.reddit.com/r/conspiracy.json').read(), \"lxml\")\n",
    "parsed_json = json.loads(soup.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = parsed_json[\"data\"]['children']\n",
    "\n",
    "title = []\n",
    "ups = []\n",
    "url = []\n",
    "plink = []\n",
    "\n",
    "for posts in data:\n",
    "    title += [posts['data']['title']]\n",
    "    ups += [posts['data']['ups']]\n",
    "    url += [posts['data']['url']]\n",
    "    plink += [posts['data']['permalink']]\n",
    "    \n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Title'] = title\n",
    "df['Upvotes'] = ups\n",
    "df['URL'] = url\n",
    "df['Permalink'] = plink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>URL</th>\n",
       "      <th>Permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clinton Coup vs. Counter-Coup</td>\n",
       "      <td>1287</td>\n",
       "      <td>https://www.reddit.com/r/conspiracy/comments/5...</td>\n",
       "      <td>/r/conspiracy/comments/5arlen/clinton_coup_vs_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Assange Interview</td>\n",
       "      <td>667</td>\n",
       "      <td>https://www.rt.com/news/365405-assange-pilger-...</td>\n",
       "      <td>/r/conspiracy/comments/5b8q8k/new_assange_inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wikileaks, in 10 years produced 10 million doc...</td>\n",
       "      <td>2912</td>\n",
       "      <td>https://i.redd.it/82r6fmulx0wx.png</td>\n",
       "      <td>/r/conspiracy/comments/5bgu7k/wikileaks_in_10_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Upvotes  \\\n",
       "0                      Clinton Coup vs. Counter-Coup     1287   \n",
       "1                              New Assange Interview      667   \n",
       "2  Wikileaks, in 10 years produced 10 million doc...     2912   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.reddit.com/r/conspiracy/comments/5...   \n",
       "1  https://www.rt.com/news/365405-assange-pilger-...   \n",
       "2                 https://i.redd.it/82r6fmulx0wx.png   \n",
       "\n",
       "                                           Permalink  \n",
       "0  /r/conspiracy/comments/5arlen/clinton_coup_vs_...  \n",
       "1  /r/conspiracy/comments/5b8q8k/new_assange_inte...  \n",
       "2  /r/conspiracy/comments/5bgu7k/wikileaks_in_10_...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(urllib2.urlopen('https://www.youtube.com/watch?v=5IuJGHuIkzY').read(), \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 403: Forbidden\n"
     ]
    }
   ],
   "source": [
    "p = []\n",
    "a = []\n",
    "for adrs in df['URL']:\n",
    "    try:\n",
    "        BeautifulSoup(urllib2.urlopen(adrs).read())\n",
    "        for idx, para in enumerate(soup.find_all('p')):\n",
    "            p += [para.text.strip()]\n",
    "        for idx, para in enumerate(soup.find_all('a')):\n",
    "            if para['href'] != '/':\n",
    "                a += [para['href']]\n",
    "    except Exception as e:\n",
    "        print e\n",
    "\n",
    "para = pd.DataFrame()\n",
    "ahref = pd.DataFrame()\n",
    "para['Paragraphs'] = p\n",
    "ahref['Links'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Cleaning..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Look through each of your words from your paragraph collecting. Remove as many of the nonsense values as you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "rejects = ['the','and','to','a','this','is','on','has','new','in', \n",
    "           'it', 'have', 'was','but','i','about','be','not','if','at',\n",
    "           'an','of','that','by','from','as','with','for','are','were','or', 'he','they','you','what','there','we','so',\n",
    "           'been','your','loading', 'working','nLoading','loading playlists','the','playlists','n','','n'','u'',' ',\n",
    "           'word','i','all','the','ago0']\n",
    "\n",
    "rejects += [str(x) for x in range(10)]\n",
    "\n",
    "def replaceText(stringy):\n",
    "    if stringy.__class__.__name__ in  ['str', 'unicode']:\n",
    "        new_stringy = re.sub(\"[^0-9a-zA-Z']\", \"\",stringy)\n",
    "        if not new_stringy:\n",
    "            return ''\n",
    "        return str(new_stringy)\n",
    "    return stringy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "for item in para['Paragraphs']:\n",
    "    words.append(item.split(' '))\n",
    "words = [item for sublist in words for item in sublist]\n",
    "words = [replaceText(x.lower()) for x in words if x not in rejects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1472"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [x for x in words if not x in rejects]\n",
    "words = [replaceText(x.lower().replace('.','')) for x in words]\n",
    "\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Now look at the links that you collected. Everything that doesn't begin with an http:// or an https:// is a direct link 99.9% of the time. Remove all links that don't begin with http:// or https://."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    https://www.google.com/get/videoqualityreport/...\n",
       "1    https://accounts.google.com/ServiceLogin?hl=en...\n",
       "2    https://accounts.google.com/ServiceLogin?hl=en...\n",
       "3    https://accounts.google.com/ServiceLogin?hl=en...\n",
       "4    https://accounts.google.com/ServiceLogin?hl=en...\n",
       "dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = []\n",
    "for i in ahref['Links']:\n",
    "    if 'http://' in i[:7]:\n",
    "        urls.append(i)\n",
    "    elif 'https://' in i[:8]:\n",
    "        urls.append(i)\n",
    "links = pd.Series(urls)\n",
    "links[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Munging (aka digging into the data)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Every thing looks good buddy. Let's total up and print the top 10 words found in each of the urls with the subreddit's title above. Be sure to note any reference to class C starships in your report. O, and don't forget to remove the unnecessary words from the total. I don't think Supreme Commander Hugh Man would like to see words like 'the' and 'and' in his report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clinton           92\n",
       "campaign          69\n",
       "dnc               69\n",
       "operative         46\n",
       "video             46\n",
       "democratic        23\n",
       "trail             23\n",
       "dirty             23\n",
       "win               23\n",
       "communications    23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in dicty2.keys():\n",
    "    btt = pd.Series(dicty2[i])\n",
    "    print 'r/conspiracy', '\\n', i,'\\n', (btt.value_counts()).sort_values(ascending=False)[:10]\n",
    "\n",
    "top_terms = pd.Series(words)\n",
    "top_terms.value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Those totals seem pretty small to me. I don't think Mr. Man's mother would approve of those results. Let's compile the words from the 10 entries with the highest upvotes. No need to print out the titles again. Just the top 10 words should be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "top_terms.value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Let's see how far this site's human tentacles spread! Print out a count of the top 10 base urls from your combined scrubbed links. \n",
    "\n",
    "___Remember a base url is everything after the first 'http://' or 'https://' and before the first '/' in a url. For example: the base url for https://www.google.com/intl/en/policies/privacy/ is www.google.com___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# These are serious bonus questions. \n",
    "<br>\n",
    "** Not for the faint of heart! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Assistant back! Good work human friend. Let's total up and print the top 10 words found in all comment sections. In addition to starships, make sure there is no mention of aliens or lizard people. We don't want to scare Mr. Man's mother with ideas that obviously aren't true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Oops! Looks like we made a mistake. The word each and both is inconveniently close in Zar... I mean English. Please find the top 10 combined word totals from the comments and urls for ___EACH___ entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Good work friend! We can now send this data back to the human lab for analysis. Until next time guy. This is Hugh Man out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"https://media.tenor.co/images/c44fc07f543327c1073653ce8e99c17e/raw\" alt=\"Title\" style=\"border: 5px solid #000000; padding: 10px; width: 250px; height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"https://media.giphy.com/media/xaMg6NGwH2fFS/giphy.gif\" alt=\"Title\" style=\"border: 5px solid #000000; padding: 10px; width: 250px; height: 200px;\"/>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
